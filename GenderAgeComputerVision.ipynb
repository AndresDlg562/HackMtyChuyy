{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sort import Sort\n",
    "\n",
    "# System\n",
    "import os\n",
    "import tempfile\n",
    "import urllib.request\n",
    "\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "# Styling\n",
    "from tqdm import tqdm  # Barra de carga\n",
    "from IPython.display import clear_output # Limpiar la salida de la celda\n",
    "from time import sleep  # Importar sleep\n",
    "\n",
    "# Deep learning\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Openvino\n",
    "import subprocess\n",
    "from openvino.runtime import Core\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos\n",
    "yolo_model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# asignar modelo de detección de rostros\n",
    "detector = \"RetinaFace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRetinaFace Citation\\n\\n@article{serengil2024lightface,\\n  title     = {A Benchmark of Facial Recognition Pipelines and Co-Usability Performances of Modules},\\n  author    = {Serengil, Sefik and Ozpinar, Alper},\\n  journal   = {Journal of Information Technologies},\\n  volume    = {17},\\n  number    = {2},\\n  pages     = {95-107},\\n  year      = {2024},\\n  doi       = {10.17671/gazibtd.1399077},\\n  url       = {https://dergipark.org.tr/en/pub/gazibtd/issue/84331/1399077},\\n  publisher = {Gazi University}\\n}\\n\\n@inproceedings{serengil2020lightface,\\n  title        = {LightFace: A Hybrid Deep Face Recognition Framework},\\n  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},\\n  booktitle    = {2020 Innovations in Intelligent Systems and Applications Conference (ASYU)},\\n  pages        = {23-27},\\n  year         = {2020},\\n  doi          = {10.1109/ASYU50717.2020.9259802},\\n  url          = {https://ieeexplore.ieee.org/document/9259802},\\n  organization = {IEEE}\\n}\\n\\n@inproceedings{serengil2021lightface,\\n  title        = {HyperExtended LightFace: A Facial Attribute Analysis Framework},\\n  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},\\n  booktitle    = {2021 International Conference on Engineering and Emerging Technologies (ICEET)},\\n  pages        = {1-4},\\n  year         = {2021},\\n  doi          = {10.1109/ICEET53442.2021.9659697},\\n  url          = {https://ieeexplore.ieee.org/document/9659697},\\n  organization = {IEEE}\\n}\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "RetinaFace Citation\n",
    "\n",
    "@article{serengil2024lightface,\n",
    "  title     = {A Benchmark of Facial Recognition Pipelines and Co-Usability Performances of Modules},\n",
    "  author    = {Serengil, Sefik and Ozpinar, Alper},\n",
    "  journal   = {Journal of Information Technologies},\n",
    "  volume    = {17},\n",
    "  number    = {2},\n",
    "  pages     = {95-107},\n",
    "  year      = {2024},\n",
    "  doi       = {10.17671/gazibtd.1399077},\n",
    "  url       = {https://dergipark.org.tr/en/pub/gazibtd/issue/84331/1399077},\n",
    "  publisher = {Gazi University}\n",
    "}\n",
    "\n",
    "@inproceedings{serengil2020lightface,\n",
    "  title        = {LightFace: A Hybrid Deep Face Recognition Framework},\n",
    "  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},\n",
    "  booktitle    = {2020 Innovations in Intelligent Systems and Applications Conference (ASYU)},\n",
    "  pages        = {23-27},\n",
    "  year         = {2020},\n",
    "  doi          = {10.1109/ASYU50717.2020.9259802},\n",
    "  url          = {https://ieeexplore.ieee.org/document/9259802},\n",
    "  organization = {IEEE}\n",
    "}\n",
    "\n",
    "@inproceedings{serengil2021lightface,\n",
    "  title        = {HyperExtended LightFace: A Facial Attribute Analysis Framework},\n",
    "  author       = {Serengil, Sefik Ilkin and Ozpinar, Alper},\n",
    "  booktitle    = {2021 International Conference on Engineering and Emerging Technologies (ICEET)},\n",
    "  pages        = {1-4},\n",
    "  year         = {2021},\n",
    "  doi          = {10.1109/ICEET53442.2021.9659697},\n",
    "  url          = {https://ieeexplore.ieee.org/document/9659697},\n",
    "  organization = {IEEE}\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(df, heatmap_path):\n",
    "    heatmap = df.groupby([\"cuadrante_x\", \"cuadrante_y\"]).size().unstack(fill_value=0)\n",
    "    heatmap = heatmap.div(heatmap.max().max())\n",
    "    heatmap = rotate(heatmap, 270)\n",
    "    \n",
    "    plt.figure(figsize=(16, 8))  # Adjusting the figure size\n",
    "    ax = sns.heatmap(heatmap, cmap=\"viridis\", cbar_kws={'label': 'Frecuencia'})\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax.set_xlabel(\"Cuadrante X\")\n",
    "    ax.set_ylabel(\"Cuadrante Y\")\n",
    "    plt.title(\"Heatmap de Frecuencia de Personas en el Video\")\n",
    "\n",
    "    # Save the heatmap as an image\n",
    "    plt.savefig(heatmap_path)\n",
    "    \n",
    "def apply_model_to_video(video_url, output_video_path, heatmap_path, last_frame_path):    \n",
    "    cap = cv2.VideoCapture(video_url)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video file\")\n",
    "        return None, None\n",
    "\n",
    "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "    heatmap = np.zeros((h, w), dtype=np.float32)\n",
    "    tracker = Sort()\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total=total_frames, desc=\"Processing Frames\")\n",
    "    grid_size = 50\n",
    "    data = []\n",
    "    last_saved_second = -1\n",
    "    \n",
    "    last_frame = None  # Para guardar el último frame\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        total_seconds = frame_number / fps\n",
    "        minutes = int(total_seconds // 60)\n",
    "        seconds = int(total_seconds % 60)\n",
    "        timestamp = f\"{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "        results = yolo_model.track(frame, persist=True)\n",
    "\n",
    "        for detection in results:\n",
    "            class_id = None\n",
    "            if (detection.boxes is not None) and (len(detection.boxes) > 0):\n",
    "                class_id = int(detection.boxes.cls[0])\n",
    "\n",
    "            if class_id == None or yolo_model.names[class_id] != \"person\":\n",
    "                continue\n",
    "\n",
    "            if yolo_model.names[class_id] != \"person\":\n",
    "                continue\n",
    "\n",
    "            box = detection.boxes.xyxy.cpu().numpy().astype(int)\n",
    "            tracks = tracker.update(box).astype(int)\n",
    "\n",
    "            for xmin, ymin, xmax, ymax, track_id in tracks:\n",
    "                # Analizamos la cara detectada con DeepFace\n",
    "                face_region = frame[ymin:ymax, xmin:xmax]\n",
    "                analysis = DeepFace.analyze(face_region, actions=['age', 'gender'], enforce_detection=False)\n",
    "                print(analysis)\n",
    "\n",
    "                if analysis:\n",
    "                    gender = analysis[0].get('gender', None)\n",
    "                    # Verificar si 'gender' es un diccionario y obtener la clave con el valor máximo\n",
    "                    if isinstance(gender, dict):\n",
    "                        gender = max(gender, key=gender.get)\n",
    "                    age = analysis[0].get('age', None)\n",
    "                    \n",
    "                    if age != 0 and gender != 0:\n",
    "                        text = f\"ID:{track_id} Age:{age}, Gender:{gender}\"\n",
    "                    elif age != 0:\n",
    "                        text = f\"ID:{track_id} Age:{age}\"\n",
    "                    elif gender != 0:\n",
    "                        text = f\"ID:{track_id} Gender:{gender}\"\n",
    "                    else:\n",
    "                        text = f\"ID:{track_id}\"\n",
    "                else:\n",
    "                    text = f\"ID:{track_id}\"\n",
    "\n",
    "                # Ajusta la posición del texto\n",
    "                text_position = (xmin, ymin - 10)  # Justo arriba del rectángulo\n",
    "\n",
    "                cv2.putText(frame, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "                grid_x = (xmin + xmax) // 2 // grid_size\n",
    "                grid_y = (ymin + ymax) // 2 // grid_size\n",
    "\n",
    "                current_second = int(total_seconds)\n",
    "                if current_second != last_saved_second:\n",
    "                    data.append({\n",
    "                        \"ID\": track_id,\n",
    "                        \"cuadrante_x\": grid_x,\n",
    "                        \"cuadrante_y\": grid_y,\n",
    "                        \"timestamp\": timestamp\n",
    "                    })\n",
    "                    last_saved_second = current_second\n",
    "\n",
    "                heatmap[ymin:ymax, xmin:xmax] += 1\n",
    "\n",
    "        heatmap_normalized = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "        heatmap_colored = cv2.applyColorMap(heatmap_normalized, cv2.COLORMAP_JET)\n",
    "        overlay = cv2.addWeighted(frame, 0.6, heatmap_colored, 0.4, 0)\n",
    "\n",
    "        for x in range(0, w, grid_size):\n",
    "            cv2.line(overlay, (x, 0), (x, h), (255, 255, 255), 1, cv2.LINE_AA)\n",
    "        for y in range(0, h, grid_size):\n",
    "            cv2.line(overlay, (0, y), (w, y), (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        \n",
    "        last_frame = overlay.copy()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        out.write(overlay)\n",
    "        pbar.update(1)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    create_heatmap(df, heatmap_path)\n",
    "    cv2.imwrite(last_frame_path, last_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rProcessing Frames:  20%|██        | 284/1413 [20:11<1:31:35,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 7 persons, 82.0ms\n",
      "Speed: 2.0ms preprocess, 82.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender: 100%|██████████| 2/2 [00:00<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'age': 38, 'region': {'x': 0, 'y': 0, 'w': 107, 'h': 65, 'left_eye': None, 'right_eye': None}, 'face_confidence': 0, 'gender': {'Woman': 12.311319261789322, 'Man': 87.68868446350098}, 'dominant_gender': 'Man'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender: 100%|██████████| 2/2 [00:00<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'age': 34, 'region': {'x': 0, 'y': 0, 'w': 95, 'h': 181, 'left_eye': None, 'right_eye': None}, 'face_confidence': 0, 'gender': {'Woman': 7.481583952903748, 'Man': 92.51841902732849}, 'dominant_gender': 'Man'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender: 100%|██████████| 2/2 [00:00<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'age': 33, 'region': {'x': 0, 'y': 0, 'w': 92, 'h': 173, 'left_eye': None, 'right_eye': None}, 'face_confidence': 0, 'gender': {'Woman': 22.95670509338379, 'Man': 77.04329490661621}, 'dominant_gender': 'Man'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender: 100%|██████████| 2/2 [00:00<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'age': 33, 'region': {'x': 0, 'y': 0, 'w': 193, 'h': 311, 'left_eye': None, 'right_eye': None}, 'face_confidence': 0, 'gender': {'Woman': 19.886426627635956, 'Man': 80.11357188224792}, 'dominant_gender': 'Man'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Apply the model to the video in this path\n",
    "urlVideo = 'https://pub-f9ef82ae3ee74240886857c6bf5f4495.r2.dev/1726401447453_whatsap.mp4'\n",
    "\n",
    "apply_model_to_video(urlVideo, \"output.mp4\", \"heatmap.png\", \"last_frame.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
